import os
from dotenv import load_dotenv
import pandas as pd
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from openai import OpenAI

load_dotenv()

# --- 1. ê²€ìƒ‰ê¸°(Retriever) ì¤€ë¹„ ---

# ëª¨ë¸ ë° ë°ì´í„° ë¡œë”© (retriever.pyì™€ ë™ì¼)
model = SentenceTransformer("jhgan/ko-sbert-nli")
df = pd.read_json("kakaobank_faq_final.json")
embeddings = np.load("faq_embeddings.npy")

# FAISS ì¸ë±ìŠ¤ ìƒì„± (retriever.pyì™€ ë™ì¼)
index = faiss.IndexFlatL2(768)
index.add(embeddings)


def search_faq(user_query, k=3):
    """ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ FAQë¥¼ kê°œ ê²€ìƒ‰"""
    query_vector = model.encode([user_query])
    D, I = index.search(query_vector, k)
    result_df = df.iloc[I[0]]
    return result_df


# --- 2. ìƒì„±ê¸°(Generator) ì¤€ë¹„ ---

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# API í‚¤ëŠ” ìë™ìœ¼ë¡œ í™˜ê²½ ë³€ìˆ˜ 'OPENAI_API_KEY'ì—ì„œ ì½ì–´ì˜µë‹ˆë‹¤.
client = OpenAI()


def generate_answer(user_query, search_results):
    """ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ LLMì„ í†µí•´ ìµœì¢… ë‹µë³€ ìƒì„±"""

    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ì€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    context = ""
    for i, row in search_results.iterrows():
        context += f"Q: {row['question']}\nA: {row['answer']}\n\n"

    # OpenAI APIì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
ë‹¹ì‹ ì€ ì¹´ì¹´ì˜¤ë±…í¬ì˜ ì¹œì ˆí•œ FAQ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ 'ì°¸ê³  ìë£Œ'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ 'ì§ˆë¬¸'ì— ëŒ€í•´ ë‹µë³€í•´ ì£¼ì„¸ìš”.
ìë£Œì— ëª…í™•í•œ ë‹µë³€ì´ ì—†ëŠ” ê²½ìš°, "ì£„ì†¡í•˜ì§€ë§Œ ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
ì ˆëŒ€ ìë£Œì— ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì„œ ë‹µë³€í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.
ë‹µë³€ì€ í•œêµ­ì–´ë¡œ, ì¹œì ˆí•˜ê³  ê°„ê²°í•˜ê²Œ í•´ì£¼ì„¸ìš”.

---
[ì°¸ê³  ìë£Œ]
{context}
---

[ì§ˆë¬¸]
{user_query}

[ë‹µë³€]
"""

    # OpenAI ChatCompletion API í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o",  # ë˜ëŠ” "gpt-4" ë“±
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹´ì¹´ì˜¤ë±…í¬ì˜ FAQ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,  # ë‹µë³€ì˜ ì°½ì˜ì„± ì¡°ì ˆ
    )

    return response.choices[0].message.content


# --- 3. ì±—ë´‡ ì‹¤í–‰ ---

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    my_question = "í•´ì™¸ ì†¡ê¸ˆ í•œë„ë¥¼ ëŠ˜ë¦¬ê³  ì‹¶ì–´ìš”"
    # my_question = "miniì¹´ë“œëŠ” ì–´ë–»ê²Œ ì‹ ì²­í•˜ë‚˜ìš”?"

    print(f"ğŸ’¬ ì‚¬ìš©ì ì§ˆë¬¸: {my_question}")

    # 1ë‹¨ê³„: ìœ ì‚¬í•œ FAQ ê²€ìƒ‰ (Retrieval)
    retrieved_docs = search_faq(my_question)
    print("  - ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ ìˆ˜:", len(retrieved_docs))

    # 2ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„± (Generation)
    final_answer = generate_answer(my_question, retrieved_docs)

    print(f"\nğŸ¤– ì±—ë´‡ ë‹µë³€:\n{final_answer}")
